version: 2.1

orbs:
  slack: circleci/slack@4.10.1

commands:
  notify_on_failure:
    steps:
      - slack/notify:
          event: fail
          channel: $SLACK_DEFAULT_CHANNEL
          template: basic_fail_1

  destroy_environment:
    description: Destroy back-end and front-end cloudformation stacks given a workflow ID.
    parameters:
      Workflow_ID:
        type: string
        default: ${CIRCLE_WORKFLOW_ID:0:7}
    steps:
      - run:
          name: Destroy environment
          when: on_fail
          command: |
            aws cloudformation delete-stack --stack-name backend-${CIRCLE_WORKFLOW_ID:0:7}
            aws s3 rm s3://udapeople-<<parameters.Workflow_ID>> --recursive
            aws cloudformation delete-stack --stack-name frontend-<< parameters.Workflow_ID >>

jobs:
  build-frontend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: [frontend-build]
      - run:
          name: Build front-end
          command: |
            cd frontend
            npm install
            npm install oauth-sign
            npm run build:prod
      - save_cache:
          paths: [frontend/node_modules]
          key: frontend-build

  build-backend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: [backend-build]
      - run:
          name: Back-end build
          command: |
            exit 1
            cd backend
            npm install
            npm run build
      - save_cache:
          paths: [backend/node_modules]
          key: backend-build
      - notify_on_failure

  test-frontend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: [frontend-build]
      - run:
          name: Test front-end
          command: |
            cd frontend
            npm i
            npm run test
  test-backend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: [backend-build]
      - run:
          name: Test Back-end
          command: |
            cd backend
            npm i
            npm run test

  scan-backend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: [backend-build]
      - run:
          name: Scan Back-end
          command: |
            cd backend
            npm i
            npm audit fix --audit-level=critical --force
            npm audit fix
            npm audit --audit-level=critical

  scan-frontend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: [frontend-build]
      - run:
          name: Scan front-end
          command: |
            cd frontend
            npm i
            npm audit fix --audit-level=critical --force
            npm audit fix
            npm audit --audit-level=critical

  deploy-infrastructure:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Install tar and gzip
          command: |
            yum install -y tar gzip
      # - run:
      #     name: Ensure back-end infrastructure exists
      #     command: |
      #       aws cloudformation deploy \
      #         --template-file .circleci/files/backend.yml \
      #         --stack-name "udapeople-backend-${CIRCLE_WORKFLOW_ID:0:7}" \
      #         --parameter-overrides ID="${CIRCLE_WORKFLOW_ID:0:7}"  \
      #         --tags project=udapeople

      - run:
          name: Ensure front-end infrastructure exist
          command: |
            aws cloudformation deploy \
              --template-file .circleci/files/frontend.yml \
              --stack-name "udapeople-backend-${CIRCLE_WORKFLOW_ID:0:7}" \
              --parameter-overrides ID="${CIRCLE_WORKFLOW_ID:0:7}"  \

      - run:
          name: Add back-end ip to ansible inventory
          command: |
            aws ec2 describe-instances --region us-east-1 --query 'Reservations[*].Instances[*].PublicIpAddress' --output text >> .circleci/ansible/inventory.txt

      - persist_to_workspace:
          root: ~/
          paths:
            - project/.circleci/ansible/inventory.txt
        # Here's where you will add some code to rollback on failure
      - destroy_environment

  configure-infrastructure:
    docker:
      - image: karimfarahat/aws-node
    steps:
      - checkout
      - add_ssh_keys:
          fingerprints: ["9a:55:de:38:47:75:23:69:74:36:fc:6f:3e:ab:a6:f4"]
      - attach_workspace:
          at: ~/
      # - run:
      #     name: "Install Dependencies"
      #     command: |
      #       apk add ansible gzip openssh-client
      - run:
          name: Configure server
          command: |
            cd .circleci/ansible
            aws ec2 describe-instances --region us-east-1 --query 'Reservations[*].Instances[*].PublicIpAddress' --output text >> inventory.txt
            cat inventory.txt
            ansible-playbook -i inventory.txt configure-server.yml
      # Here's where you will add some code to rollback on failure

workflows:
  default:
    jobs:
      # - build-frontend
      # - build-backend
      # - test-frontend:
      #     requires: [build-frontend]
      # - test-backend:
      #     requires: [build-backend]
      # - scan-backend:
      #     requires: [build-backend]
      # - scan-frontend:
      #     requires: [build-frontend]
      - deploy-infrastructure:
          requires: [test-frontend, test-backend, scan-frontend, scan-backend]
          filters:
            branches:
              only: [master]
      - configure-infrastructure:
          requires: [deploy-infrastructure]
